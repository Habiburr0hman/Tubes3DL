{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17b545c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import requests\n",
    "\n",
    "import technical_analysis\n",
    "from technical_analysis import moving_average, indicators \n",
    "import ta\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "import pandas_ta\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14c981fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = 'SVIS9RVCW1LBU6B5'\n",
    "# # 'https://www.alphavantage.co/query?function=SMA&symbol=IBM&interval=weekly&time_period=10&series_type=open&apikey={API_KEY}'\n",
    "# # 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&outputsize=full&apikey={API_KEY}&datatype=csv'\n",
    "\n",
    "# name = 'NVDA'\n",
    "\n",
    "# intervals = [i for i in range(1, 91)]\n",
    "# for i in intervals:\n",
    "#     url = f'https://www.alphavantage.co/query?function=SMA&symbol={name}&interval=daily&time_period={i}&series_type=close&apikey={API_KEY}&data_type=csv'\n",
    "#     r = requests.get(url)\n",
    "#     content = r.content\n",
    "#     f = open(f'{name}_SMA_{i}.csv', 'wb')\n",
    "#     f.write(content)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee63a815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>21.75</td>\n",
       "      <td>24.3800</td>\n",
       "      <td>21.75</td>\n",
       "      <td>23.50</td>\n",
       "      <td>1630300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>23.94</td>\n",
       "      <td>25.1300</td>\n",
       "      <td>23.75</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1744800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>26.00</td>\n",
       "      <td>28.1300</td>\n",
       "      <td>25.81</td>\n",
       "      <td>27.44</td>\n",
       "      <td>4191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>27.75</td>\n",
       "      <td>29.9400</td>\n",
       "      <td>27.75</td>\n",
       "      <td>29.19</td>\n",
       "      <td>2625700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.2500</td>\n",
       "      <td>26.88</td>\n",
       "      <td>28.25</td>\n",
       "      <td>1284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>1136.21</td>\n",
       "      <td>1150.0000</td>\n",
       "      <td>1120.03</td>\n",
       "      <td>1150.00</td>\n",
       "      <td>43839176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>1157.16</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1140.45</td>\n",
       "      <td>1164.37</td>\n",
       "      <td>40332401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187</th>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>1183.71</td>\n",
       "      <td>1224.4950</td>\n",
       "      <td>1174.68</td>\n",
       "      <td>1224.40</td>\n",
       "      <td>52840178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>1240.48</td>\n",
       "      <td>1255.8700</td>\n",
       "      <td>1183.20</td>\n",
       "      <td>1209.98</td>\n",
       "      <td>66469619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>1197.70</td>\n",
       "      <td>1216.9171</td>\n",
       "      <td>1180.22</td>\n",
       "      <td>1208.88</td>\n",
       "      <td>41238580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6190 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp     open       high      low    close    volume\n",
       "0     1999-11-01    21.75    24.3800    21.75    23.50   1630300\n",
       "1     1999-11-02    23.94    25.1300    23.75    25.00   1744800\n",
       "2     1999-11-03    26.00    28.1300    25.81    27.44   4191000\n",
       "3     1999-11-04    27.75    29.9400    27.75    29.19   2625700\n",
       "4     1999-11-05    30.00    30.2500    26.88    28.25   1284100\n",
       "...          ...      ...        ...      ...      ...       ...\n",
       "6185  2024-06-03  1136.21  1150.0000  1120.03  1150.00  43839176\n",
       "6186  2024-06-04  1157.16  1166.0000  1140.45  1164.37  40332401\n",
       "6187  2024-06-05  1183.71  1224.4950  1174.68  1224.40  52840178\n",
       "6188  2024-06-06  1240.48  1255.8700  1183.20  1209.98  66469619\n",
       "6189  2024-06-07  1197.70  1216.9171  1180.22  1208.88  41238580\n",
       "\n",
       "[6190 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('daily_NVDA.csv')\n",
    "df = df.sort_values('timestamp').reset_index().drop('index', axis=1)\n",
    "\n",
    "init_cols = list(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cacfafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [i for i in range(3, 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee9aea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\1033385826.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n"
     ]
    }
   ],
   "source": [
    "for i in intervals:\n",
    "    df[f'sma_{i}'] = moving_average.sma(price=df['close'], period=i)\n",
    "    df[f'ema_{i}'] = moving_average.ema(price=df['close'], period=i)\n",
    "    df[f'tma_{i}'] = moving_average.tma(price=df['close'], period=i)\n",
    "    df[f'lwma_{i}'] = moving_average.lwma(price=df['close'], period=i)\n",
    "    df[f'wilderma_{i}'] = moving_average.wilder_ma(price=df['close'], period=i)\n",
    "    df[f'kama_{i}'] = moving_average.kama(price=df['close'], period=i, min_smoothing_constant=3, max_smoothing_constant=30)\n",
    "    df[f'gma_{i}']= moving_average.gma(price=df['close'], period=i)\n",
    "#     df[f'dema_{i}'] = moving_average.double_ema(price=df['close'], period=i)\n",
    "#     df[f'tema_{i}'] = moving_average.triple_ema(price=df['close'], period=i)\n",
    "    \n",
    "    df[f'atr_{i}'] = indicators.atr(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
    "    df[f'rsi_{i}'] = indicators.rsi(price=df['close'], period=i)\n",
    "    df[f'willr_{i}'] = indicators.perc_r(high=df['high'], low=df['low'], close=df['close'], period=i)\n",
    "    df[f'trix_{i}'] = indicators.trix(price=df['close'], period=i)\n",
    "    df[f'roc_{i}'] = indicators.roc(price=df['close'], period=i)\n",
    "    df[f'std_{i}'] = indicators.std(price=df['close'], period=i)\n",
    "    \n",
    "# df[f'tsi'] = indicators.tsi(price=df['close'], period1=25, period2=13) # standard parameter\n",
    "# df[f'macd'] = indicators.macd(price=df['close'], return_histogram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23a61485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
      "C:\\Users\\Habiburrohman\\AppData\\Local\\Temp\\ipykernel_10544\\44779781.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)\n"
     ]
    }
   ],
   "source": [
    "for i in intervals:\n",
    "    df[f'ppo_{i}'] = pandas_ta.cmo(close=df['close'], length=i)\n",
    "    df[f'hma_{i}'] = pandas_ta.hma(close=df['close'], length=i)\n",
    "    df[f'wma_{i}'] = pandas_ta.wma(close=df['close'], length=i)\n",
    "    df[f'tema_{i}'] = pandas_ta.tema(close=df['close'], length=i)\n",
    "    df[f'cci_{i}'] = pandas_ta.cci(high=df['high'], low=df['low'], close=df['close'], length=i)\n",
    "    df[f'cmf_{i}'] = pandas_ta.cmf(high=df['high'], low=df['low'], volume=df['volume'], close=df['close'], length=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "306c2974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6190 entries, 0 to 6189\n",
      "Columns: 367 entries, timestamp to cmf_21\n",
      "dtypes: float64(365), int64(1), object(1)\n",
      "memory usage: 17.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a024ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6190 entries, 0 to 6189\n",
      "Columns: 367 entries, timestamp to trix_21\n",
      "dtypes: float64(365), int64(1), object(1)\n",
      "memory usage: 17.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (6190, 367))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'macd', 'tsi'\n",
    "ordered_indicators = ['std', 'sma', 'ema', 'tema', 'tma', 'lwma', 'wilderma', 'kama', 'gma', 'hma', 'wma', \n",
    "                      'rsi', 'willr', 'cci', 'cmf', 'ppo', 'roc', 'atr', 'trix']\n",
    "\n",
    "ordered_cols = init_cols\n",
    "for indicator in ordered_indicators:\n",
    "    ordered_cols.extend([f'{indicator}_{i}' for i in intervals])\n",
    "\n",
    "df = df.reindex(ordered_cols, axis=1)\n",
    "df.info(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bf14609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_labels(self, df, col_name, window_size=11):\n",
    "#     \"\"\"\n",
    "#     Data is labeled as per the logic in research paper\n",
    "#     Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "#     params :\n",
    "#         df => Dataframe with data\n",
    "#         col_name => name of column which should be used to determine strategy\n",
    "#     returns : numpy array with integer codes for labels with\n",
    "#                   size = total-(window_size)+1\n",
    "#     \"\"\"\n",
    "\n",
    "#     self.log(\"creating label with original paper strategy\")\n",
    "#     row_counter = 0\n",
    "#     total_rows = len(df)\n",
    "#     labels = np.zeros(total_rows)\n",
    "#     labels[:] = np.nan\n",
    "#     print(\"Calculating labels\")\n",
    "#     pbar = tqdm(total=total_rows)\n",
    "\n",
    "#     while row_counter < total_rows:\n",
    "#         if row_counter >= window_size - 1:\n",
    "#             window_begin = row_counter - (window_size - 1)\n",
    "#             window_end = row_counter\n",
    "#             window_middle = (window_begin + window_end) / 2\n",
    "\n",
    "#             min_ = np.inf\n",
    "#             min_index = -1\n",
    "#             max_ = -np.inf\n",
    "#             max_index = -1\n",
    "#             for i in range(window_begin, window_end + 1):\n",
    "#                 price = df.iloc[i][col_name]\n",
    "#                 if price < min_:\n",
    "#                     min_ = price\n",
    "#                     min_index = i\n",
    "#                 if price > max_:\n",
    "#                     max_ = price\n",
    "#                     max_index = i\n",
    "\n",
    "#             if max_index == window_middle:\n",
    "#                 labels[window_middle] = 0\n",
    "#             elif min_index == window_middle:\n",
    "#                 labels[window_middle] = 1\n",
    "#             else:\n",
    "#                 labels[window_middle] = 2\n",
    "\n",
    "#         row_counter = row_counter + 1\n",
    "#         pbar.update(1)\n",
    "\n",
    "#     pbar.close()\n",
    "#     return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0b532c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(df, col_name, window_size=11):\n",
    "    \"\"\"\n",
    "    Data is labeled as per the logic in research paper\n",
    "    Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "    params :\n",
    "        df => Dataframe with data\n",
    "        col_name => name of column which should be used to determine strategy\n",
    "\n",
    "    returns : numpy array with integer codes for labels with\n",
    "                  size = total-(window_size)+1\n",
    "    \"\"\"\n",
    "\n",
    "    row_counter = 0\n",
    "    total_rows = len(df)\n",
    "    labels = np.zeros(total_rows)\n",
    "    labels[:] = np.nan\n",
    "    print(\"Calculating labels\")\n",
    "    pbar = tqdm(total=total_rows)\n",
    "\n",
    "    while row_counter < total_rows:\n",
    "        if row_counter >= window_size - 1:\n",
    "            window_begin = row_counter - (window_size - 1)\n",
    "            window_end = row_counter\n",
    "            window_middle = (window_begin + window_end) // 2\n",
    "\n",
    "            min_ = np.inf\n",
    "            min_index = -1\n",
    "            max_ = -np.inf\n",
    "            max_index = -1\n",
    "            for i in range(window_begin, window_end + 1):\n",
    "                price = df.iloc[i][col_name]\n",
    "                if price < min_:\n",
    "                    min_ = price\n",
    "                    min_index = i\n",
    "                if price > max_:\n",
    "                    max_ = price\n",
    "                    max_index = i\n",
    "\n",
    "            if max_index == window_middle:\n",
    "                labels[window_middle] = 0\n",
    "            elif min_index == window_middle:\n",
    "                labels[window_middle] = 1\n",
    "            else:\n",
    "                labels[window_middle] = 2\n",
    "\n",
    "        row_counter = row_counter + 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d09810bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6190/6190 [00:38<00:00, 161.06it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = create_labels(df, 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1b54d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6190, 368)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = labels\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bece34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(df.columns):\n",
    "    if(sum(pd.isna(df[col])) == len(df)):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ad20748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6156, 368)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e8d7ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000000276"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc['max']['cci_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2a99fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['labels'].values\n",
    "np.save('y', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5b422f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 361\n",
      "train_split = 0.7\n",
      "Shape of x, y train/cv/test (3446, 361) (3446,) (1478, 361) (1478,) (1232, 361) (1232,)\n"
     ]
    }
   ],
   "source": [
    "list_features = list(df.loc[:, 'std_3':'trix_21'].columns)\n",
    "print('Total number of features:', len(list_features))\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'std_3':'trix_21'].values, df['labels'].values, train_size=0.8, \n",
    "                                                    test_size=0.2, random_state=2, shuffle=True, stratify=df['labels'].values)\n",
    "\n",
    "if 0.7*x_train.shape[0] < 2500:\n",
    "    train_split = 0.8\n",
    "else:\n",
    "    train_split = 0.7\n",
    "\n",
    "print('train_split =',train_split)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, train_size=train_split, test_size=1-train_split, \n",
    "                                                random_state=2, shuffle=True, stratify=y_train)\n",
    "mm_scaler = MinMaxScaler(feature_range=(-1, 1)) # or StandardScaler?\n",
    "x_train = mm_scaler.fit_transform(x_train)\n",
    "x_cv = mm_scaler.transform(x_cv)\n",
    "x_test = mm_scaler.transform(x_test)\n",
    "\n",
    "# s_scaler = MinMaxScalerScaler(with_mean=0, with_std=1)\n",
    "# x_train = s_scaler.fit_transform(x_train)\n",
    "# x_cv = s_scaler.transform(x_cv)\n",
    "# x_test = s_scaler.transform(x_test)\n",
    "\n",
    "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "049b2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_as_image(x, img_width, img_height):\n",
    "    x_temp = np.zeros((len(x), img_height, img_width))\n",
    "    for i in range(x.shape[0]):\n",
    "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
    "\n",
    "    return x_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6c78ad4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape of x, y train/test (3446, 19, 19, 3) (3446,) (1232, 19, 19, 3) (1232,)\n"
     ]
    }
   ],
   "source": [
    "num_features = len(list_features)\n",
    "dim = int(np.sqrt(num_features))\n",
    "x_train = reshape_as_image(x_train, dim, dim)\n",
    "x_cv = reshape_as_image(x_cv, dim, dim)\n",
    "x_test = reshape_as_image(x_test, dim, dim)\n",
    "# adding a 1-dim for channels (3)\n",
    "x_train = np.stack((x_train,) * 3, axis=-1)\n",
    "x_test = np.stack((x_test,) * 3, axis=-1)\n",
    "x_cv = np.stack((x_cv,) * 3, axis=-1)\n",
    "print(\"final shape of x, y train/test {} {} {} {}\".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78201b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3732018, True)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('x_train', x_train)\n",
    "np.save('x_cv', x_cv)\n",
    "np.save('x_test', x_test)\n",
    "np.save('y_train', y_train)\n",
    "np.save('y_cv', y_cv)\n",
    "np.save('y_test', y_test)\n",
    "\n",
    "dat = np.load('x_train.npy')\n",
    "sum(sum(sum(sum(dat == x_train)))), x_train.shape == dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73844cf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The proto value '6' is already registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import os\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# import sys\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# import time\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# import pandas as pd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# from sklearn.metrics import confusion_matrix, f1_score\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m value_lib\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backprop_util\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\values.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m struct_pb2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:206\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_ctx \u001b[38;5;28;01mas\u001b[39;00m autograph_ctx\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m autograph\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_autograph\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m debug_mode\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iterator_ops\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:991\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop):\n\u001b[0;32m    987\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m gen_dataset_ops\u001b[38;5;241m.\u001b[39mdeserialize_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop, restored_tensors[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    990\u001b[0m nested_structure_coder\u001b[38;5;241m.\u001b[39mregister_codec(\n\u001b[1;32m--> 991\u001b[0m     \u001b[43mnested_structure_coder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuiltInTypeSpecCodec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIteratorSpec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTypeSpecProto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA_ITERATOR_SPEC\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    994\u001b[0m )\n\u001b[0;32m    997\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `tf.data.Iterator.get_next_as_optional()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    999\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.experimental.get_next_as_optional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next_as_optional\u001b[39m(iterator):\n\u001b[0;32m   1001\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `tf.experimental.Optional` with the next element of the iterator.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \n\u001b[0;32m   1003\u001b[0m \u001b[38;5;124;03m  If the iterator has reached the end of the sequence, the returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03m    of the iterator (if it exists) or no value.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\nested_structure_coder.py:387\u001b[0m, in \u001b[0;36mBuiltInTypeSpecCodec.__init__\u001b[1;34m(self, type_spec_class, type_spec_proto_enum)\u001b[0m\n\u001b[0;32m    383\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already has an instantiated codec.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_spec_proto_enum \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_BUILT_IN_TYPE_SPEC_PROTOS:\n\u001b[1;32m--> 387\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe proto value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_proto_enum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m   )\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(type_spec_proto_enum, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m type_spec_proto_enum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m type_spec_proto_enum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m    394\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe proto value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_proto_enum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is invalid.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The proto value '6' is already registered."
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import time\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LeakyReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.initializers import RandomUniform, RandomNormal\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from logger import Logger\n",
    "from secrets import api_key\n",
    "from utils import download_save, seconds_to_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "23ee1a92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The proto value '6' is already registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [98]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, f1_score\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model, Model\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m value_lib\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backprop_util\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\values.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m struct_pb2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:206\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_ctx \u001b[38;5;28;01mas\u001b[39;00m autograph_ctx\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m autograph\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_autograph\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m debug_mode\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iterator_ops\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:991\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop):\n\u001b[0;32m    987\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m gen_dataset_ops\u001b[38;5;241m.\u001b[39mdeserialize_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop, restored_tensors[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    990\u001b[0m nested_structure_coder\u001b[38;5;241m.\u001b[39mregister_codec(\n\u001b[1;32m--> 991\u001b[0m     \u001b[43mnested_structure_coder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuiltInTypeSpecCodec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIteratorSpec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTypeSpecProto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA_ITERATOR_SPEC\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    994\u001b[0m )\n\u001b[0;32m    997\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `tf.data.Iterator.get_next_as_optional()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    999\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.experimental.get_next_as_optional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next_as_optional\u001b[39m(iterator):\n\u001b[0;32m   1001\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `tf.experimental.Optional` with the next element of the iterator.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \n\u001b[0;32m   1003\u001b[0m \u001b[38;5;124;03m  If the iterator has reached the end of the sequence, the returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03m    of the iterator (if it exists) or no value.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\nested_structure_coder.py:387\u001b[0m, in \u001b[0;36mBuiltInTypeSpecCodec.__init__\u001b[1;34m(self, type_spec_class, type_spec_proto_enum)\u001b[0m\n\u001b[0;32m    383\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already has an instantiated codec.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_spec_proto_enum \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_BUILT_IN_TYPE_SPEC_PROTOS:\n\u001b[1;32m--> 387\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe proto value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_proto_enum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m   )\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(type_spec_proto_enum, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m type_spec_proto_enum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m type_spec_proto_enum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m    394\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe proto value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_spec_proto_enum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is invalid.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The proto value '6' is already registered."
     ]
    }
   ],
   "source": [
    "def f1_weighted(y_true, y_pred):\n",
    "    y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)  # can use conf_mat[0, :], tf.slice()\n",
    "    # precision = TP/TP+FP, recall = TP/TP+FN\n",
    "    rows, cols = conf_mat.get_shape()\n",
    "    size = y_true_class.get_shape()[0]\n",
    "    precision = tf.constant([0, 0, 0])  # change this to use rows/cols as size\n",
    "    recall = tf.constant([0, 0, 0])\n",
    "    class_counts = tf.constant([0, 0, 0])\n",
    "\n",
    "    def get_precision(i, conf_mat):\n",
    "        print(\"prec check\", conf_mat, conf_mat[i, i], tf.reduce_sum(conf_mat[:, i]))\n",
    "        precision[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[:, i]))\n",
    "        recall[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[i, :]))\n",
    "        tf.add(i, 1)\n",
    "        return i, conf_mat, precision, recall\n",
    "\n",
    "    def tf_count(i):\n",
    "        elements_equal_to_value = tf.equal(y_true_class, i)\n",
    "        as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "        count = tf.reduce_sum(as_ints)\n",
    "        class_counts[i].assign(count)\n",
    "        tf.add(i, 1)\n",
    "        return count\n",
    "\n",
    "    def condition(i, conf_mat):\n",
    "        return tf.less(i, 3)\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    i, conf_mat = tf.while_loop(condition, get_precision, [i, conf_mat])\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    c = lambda i: tf.less(i, 3)\n",
    "    b = tf_count(i)\n",
    "    tf.while_loop(c, b, [i])\n",
    "\n",
    "    weights = tf.math.divide(class_counts, size)\n",
    "    numerators = tf.math.multiply(tf.math.multiply(precision, recall), tf.constant(2))\n",
    "    denominators = tf.math.add(precision, recall)\n",
    "    f1s = tf.math.divide(numerators, denominators)\n",
    "    weighted_f1 = tf.reduce_sum(tf.math.multiply(f1s, weights))\n",
    "    return weighted_f1\n",
    "\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    this calculates precision & recall\n",
    "    \"\"\"\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # mistake: y_pred of 0.3 is also considered 1\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    # y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    # y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    # conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)\n",
    "    # tf.Print(conf_mat, [conf_mat], \"confusion_matrix\")\n",
    "\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "get_custom_objects().update({\"f1_metric\": f1_metric, \"f1_weighted\": f1_weighted})\n",
    "\n",
    "params = {'batch_size': 60, 'conv2d_layers': {'conv2d_do_1': 0.0, 'conv2d_filters_1': 30,\n",
    "                                               'conv2d_kernel_size_1': 2, 'conv2d_mp_1': 2, 'conv2d_strides_1': 1,\n",
    "                                               'kernel_regularizer_1':0.0, 'conv2d_do_2': 0.01, 'conv2d_filters_2': 10,\n",
    "                                               'conv2d_kernel_size_2': 2, 'conv2d_mp_2': 2, 'conv2d_strides_2': 2,\n",
    "                                               'kernel_regularizer_2':0.0, 'layers': 'two'},\n",
    "           'dense_layers': {'dense_do_1': 0.07, 'dense_nodes_1': 100, 'kernel_regularizer_1':0.0, 'layers': 'one'},\n",
    "           'epochs': 3000, 'lr': 0.001, 'optimizer': 'adam', 'input_dim_1': 15, 'input_dim_2': 15, 'input_dim_3': 3}\n",
    "\n",
    "\n",
    "def create_model_cnn(params):\n",
    "    model = Sequential()\n",
    "\n",
    "    print(\"Training with params {}\".format(params))\n",
    "    # (batch_size, timesteps, data_dim)\n",
    "    # x_train, y_train = get_data_cnn(df, df.head(1).iloc[0][\"timestamp\"])[0:2]\n",
    "    conv2d_layer1 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_1\"],\n",
    "                           params[\"conv2d_layers\"][\"conv2d_kernel_size_1\"],\n",
    "                           strides=params[\"conv2d_layers\"][\"conv2d_strides_1\"],\n",
    "                           kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_1\"]),\n",
    "                           padding='valid', activation=\"relu\", use_bias=True,\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           input_shape=(params['input_dim_1'],\n",
    "                                        params['input_dim_2'], params['input_dim_3']))\n",
    "    model.add(conv2d_layer1)\n",
    "    if params[\"conv2d_layers\"]['conv2d_mp_1'] == 1:\n",
    "        model.add(MaxPool2D(pool_size=2))\n",
    "    model.add(Dropout(params['conv2d_layers']['conv2d_do_1']))\n",
    "    if params[\"conv2d_layers\"]['layers'] == 'two':\n",
    "        conv2d_layer2 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_2\"],\n",
    "                               params[\"conv2d_layers\"][\"conv2d_kernel_size_2\"],\n",
    "                               strides=params[\"conv2d_layers\"][\"conv2d_strides_2\"],\n",
    "                               kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_2\"]),\n",
    "                               padding='valid', activation=\"relu\", use_bias=True,\n",
    "                               kernel_initializer='glorot_uniform')\n",
    "        model.add(conv2d_layer2)\n",
    "        if params[\"conv2d_layers\"]['conv2d_mp_2'] == 1:\n",
    "            model.add(MaxPool2D(pool_size=2))\n",
    "        model.add(Dropout(params['conv2d_layers']['conv2d_do_2']))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(params['dense_layers'][\"dense_nodes_1\"], activation='relu'))\n",
    "    model.add(Dropout(params['dense_layers']['dense_do_1']))\n",
    "\n",
    "    if params['dense_layers'][\"layers\"] == 'two':\n",
    "        model.add(Dense(params['dense_layers'][\"dense_nodes_2\"], activation='relu',\n",
    "                        kernel_regularizer=params['dense_layers'][\"kernel_regularizer_1\"]))\n",
    "        model.add(Dropout(params['dense_layers']['dense_do_2']))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    if params[\"optimizer\"] == 'rmsprop':\n",
    "        optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    elif params[\"optimizer\"] == 'sgd':\n",
    "        optimizer = optimizers.SGD(lr=params[\"lr\"], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    elif params[\"optimizer\"] == 'adam':\n",
    "        optimizer = optimizers.Adam(learning_rate=params[\"lr\"], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_metric])\n",
    "    # from keras.utils.vis_utils import plot_model use this too for diagram with plot\n",
    "    model.summary(print_fn=lambda x: print(x + '\\n'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def check_baseline(pred, y_test):\n",
    "    e = np.equal(pred, y_test)\n",
    "    print(\"TP class counts\", np.unique(y_test[e], return_counts=True))\n",
    "    print(\"True class counts\", np.unique(y_test, return_counts=True))\n",
    "    print(\"Pred class counts\", np.unique(pred, return_counts=True))\n",
    "    holds = np.unique(y_test, return_counts=True)[1][2]  # number 'hold' predictions\n",
    "    logger.append_log(\"baseline acc:\", str((holds / len(y_test) * 100)))\n",
    "\n",
    "\n",
    "model = create_model_cnn(params)\n",
    "best_model_path = os.path.join('best_model_keras')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                   patience=100, min_delta=0.0001)\n",
    "# csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'log_training_batch.log'), append=True)\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=10, verbose=1, mode='min',\n",
    "                        min_delta=0.001, cooldown=1, min_lr=0.0001)\n",
    "mcp = ModelCheckpoint(best_model_path, monitor='val_loss', verbose=0,\n",
    "                      save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(history.history['f1_metric'])\n",
    "    plt.plot(history.history['val_f1_metric'])\n",
    "    plt.title('Model Metrics')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train_loss', 'val_loss', 'train_acc', 'val_acc', 'f1', 'val_f1'], loc='upper left')\n",
    "    plt.savefig(os.path.join('plt_{}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddfda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.append_log(\"training for batch number {}\")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=params['epochs'], verbose=0,\n",
    "                    batch_size=64, shuffle=True,\n",
    "                    validation_data=(x_cv, y_cv),\n",
    "                    callbacks=[es, mcp, rlp])\n",
    "\n",
    "plot_history(history)\n",
    "min_arg = np.argmin(np.array(history.history['val_loss']))\n",
    "logger.append_log(\"Best val_loss is {} and corresponding train_loss is {}\".format(\n",
    "    history.history['val_loss'][min_arg], history.history['loss'][min_arg]))\n",
    "test_res = model.evaluate(x_test, y_test, verbose=0)\n",
    "logger.append_log(\"keras evaluate result =\" + str(test_res)+\", metrics:\"+str(model.metrics_names))\n",
    "pred = model.predict(x_test)\n",
    "check_baseline(np.argmax(pred, axis=1), np.argmax(y_test, axis=1))\n",
    "conf_mat = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(pred, axis=1))\n",
    "logger.append_log('\\n'+str(conf_mat))\n",
    "labels = [0, 1, 2]\n",
    "f1_weighted = f1_score(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), labels=None,\n",
    "                        average='weighted', sample_weight=None)\n",
    "logger.append_log(\"F1 score (weighted) \" + str(f1_weighted))\n",
    "logger.append_log(\n",
    "    \"F1 score (macro) \" + str(f1_score(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), labels=None,\n",
    "                                        average='macro', sample_weight=None)))\n",
    "logger.append_log(\n",
    "    \"F1 score (micro) \" + str(f1_score(np.argmax(y_test, axis=1), np.argmax(pred, axis=1), labels=None,\n",
    "                                        aerage='micro',\n",
    "                                        sample_weight=None)))  # weighted and micro preferred in case of imbalance\n",
    "\n",
    "for i, row in enumerate(conf_mat):\n",
    "    logger.append_log(\"precision of class {} = {}\".format(i, np.round(row[i] / np.sum(row), 2)))\n",
    "\n",
    "logger.append_log(\"Complete training finished in {}\".format(seconds_to_minutes(time.time() - start_time)))\n",
    "logger.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
